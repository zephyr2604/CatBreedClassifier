{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cat Breed Classifier.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPnY5BlgMtkjlAe1auJT0Q6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"S05TX-ZQoH_x"},"source":["###Importing Torch"]},{"cell_type":"code","metadata":{"id":"yju-kJO6mZLF","executionInfo":{"status":"ok","timestamp":1637700262241,"user_tz":-330,"elapsed":342,"user":{"displayName":"Aaqib Syed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_BX0KY_ErNz6BNYJpNQC7znAJ4M92_BbrEkuHfg=s64","userId":"07753144630154178987"}}},"source":["import torch\n","\n","\n","class Model(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, n_classes):\n","        super().__init__()\n","        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n","        self.relu1 = torch.nn.ReLU()\n","        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim // 2)\n","        self.relu2 = torch.nn.ReLU()\n","        self.fc3 = torch.nn.Linear(hidden_dim // 2, n_classes)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu1(x)\n","        x = self.fc2(x)\n","        x = self.relu2(x)\n","        x = self.fc3(x)\n","        return x\n"],"execution_count":55,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IxoXOD0V3Kj3"},"source":["### Model Initialization\n","\n"]},{"cell_type":"code","metadata":{"id":"oTzVkrs3pFcF","executionInfo":{"status":"ok","timestamp":1637700265209,"user_tz":-330,"elapsed":1316,"user":{"displayName":"Aaqib Syed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_BX0KY_ErNz6BNYJpNQC7znAJ4M92_BbrEkuHfg=s64","userId":"07753144630154178987"}}},"source":["import torchvision\n","\n","\n","classifier = torchvision.models.resnet50(pretrained=True)\n","classifier.fc = Model(input_dim=2048, hidden_dim=1024, n_classes=12)"],"execution_count":56,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UvcIskDntWQ2"},"source":["### Mount drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MeNs43BktZKl","executionInfo":{"status":"ok","timestamp":1637700265209,"user_tz":-330,"elapsed":9,"user":{"displayName":"Aaqib Syed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_BX0KY_ErNz6BNYJpNQC7znAJ4M92_BbrEkuHfg=s64","userId":"07753144630154178987"}},"outputId":"d6f7bd53-8d79-4afe-8786-21a4a6fa623d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"OcMTdh5j3QHr"},"source":["### Training the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vuoS9FrFsk6R","outputId":"3cf71450-7b65-4404-8461-8e0840cd442e"},"source":["import os\n","\n","import torch\n","import torchvision\n","from sklearn.metrics import classification_report, f1_score\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}.')\n","\n","# Transformations\n","transform_rotation = torchvision.transforms.RandomApply([\n","    torchvision.transforms.RandomRotation(20)\n","], p=0.2)\n","\n","transform_train = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize(256),\n","    torchvision.transforms.CenterCrop(224),\n","    torchvision.transforms.RandomPerspective(distortion_scale=0.1, p=0.2),\n","    transform_rotation,\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","])\n","\n","transform_valid = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize(256),\n","    torchvision.transforms.CenterCrop(224),\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","])\n","\n","# DataLoaders\n","TRAIN_DATA_DIR = 'drive/MyDrive/data/train'\n","VALID_DATA_DIR = 'drive/MyDrive/data/valid'\n","TEST_DATA_DIR = 'drive/MyDrive/data/test'\n","\n","BATCH_SIZE = 32\n","\n","train_data = torchvision.datasets.ImageFolder(TRAIN_DATA_DIR,\n","                                              transform=transform_train,\n","                                              is_valid_file=lambda x: x.endswith('.jpg'))\n","\n","valid_data = torchvision.datasets.ImageFolder(VALID_DATA_DIR,\n","                                              transform=transform_valid,\n","                                              is_valid_file=lambda x: x.endswith('.jpg'))\n","\n","test_data = torchvision.datasets.ImageFolder(TEST_DATA_DIR,\n","                                             transform=transform_valid,\n","                                             is_valid_file=lambda x: x.endswith('.jpg'))\n","\n","train_data_loader = torch.utils.data.DataLoader(\n","    train_data,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=0,\n",")\n","\n","valid_data_loader = torch.utils.data.DataLoader(\n","    valid_data,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=0,\n",")\n","\n","test_data_loader = torch.utils.data.DataLoader(\n","    test_data,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=0,\n",")\n","\n","# Model\n","\n","# initialize model\n","model = torchvision.models.resnet50(pretrained=True).to(device)\n","\n","# freeze the backbone\n","for parameter in model.parameters():\n","    parameter.requires_grad = False\n","\n","\n","class Model(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, n_classes):\n","        super(Model, self).__init__()\n","        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n","        self.relu1 = torch.nn.ReLU()\n","        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim // 2)\n","        self.relu2 = torch.nn.ReLU()\n","        self.fc3 = torch.nn.Linear(hidden_dim // 2, n_classes)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu1(x)\n","        x = self.fc2(x)\n","        x = self.relu2(x)\n","        x = self.fc3(x)\n","        return x\n","\n","\n","model.fc = Model(2048, 1024, 12)\n","model.fc.to(device)\n","\n","# Training\n","MODEL_SAVE_PATH = 'drive/MyDrive/checkpoints'\n","\n","LEARNING_RATE = 1e-3\n","N_EPOCHS = 2\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","\n","def train(model, n_epochs, criterion, optimizer, train_data_loader, valid_data_loader,\n","          device, model_save_path, logging_interval: int = 50):\n","    best_valid_f1_score = 0.0\n","    os.makedirs(model_save_path, exist_ok=True)\n","\n","    for epoch in range(n_epochs):\n","        # training step\n","        model.train()\n","\n","        for batch_idx, (batch_data, batch_labels) in enumerate(train_data_loader):\n","            inputs = batch_data.to(device)\n","            y_true = batch_labels.to(device)\n","\n","            # Initialize the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimizer step\n","            y_pred = model(inputs)\n","            loss = criterion(y_pred, y_true)\n","            loss.backward()\n","            optimizer.step()\n","\n","            if (batch_idx + 1) % logging_interval == 0:\n","                print(f'Epoch: {epoch + 1}\\t| Batch: {batch_idx + 1}\\t| Loss: {loss}')\n","\n","        # validation step\n","        model.eval()\n","        y_true = []\n","        y_pred = []\n","        for valid_data, valid_labels in valid_data_loader:\n","            valid_data = valid_data.to(device)\n","            valid_labels = valid_labels.to(device)\n","            with torch.no_grad():\n","                valid_preds = model(valid_data)\n","            valid_pred_labels = torch.argmax(valid_preds, dim=1)\n","            y_true.extend(valid_labels.detach().cpu().numpy())\n","            y_pred.extend(valid_pred_labels.detach().cpu().numpy())\n","        valid_f1_score = f1_score(y_true, y_pred, average='macro')\n","\n","        if valid_f1_score > best_valid_f1_score:\n","            best_valid_f1_score = valid_f1_score\n","            torch.save(model.state_dict(),\n","                       os.path.join(model_save_path, 'best_checkpoint.pth'))\n","        print(f'Epoch {epoch + 1} F1-score: {valid_f1_score}\\t| Best F1-score: {best_valid_f1_score}')\n","        torch.save(model.state_dict(),\n","                   os.path.join(model_save_path, f'epoch_{epoch + 1}_checkpoint.pth'))\n","\n","\n","train(model, N_EPOCHS, criterion, optimizer,\n","      train_data_loader, valid_data_loader,\n","      device, MODEL_SAVE_PATH)\n","\n","# Testing\n","model.load_state_dict(torch.load(os.path.join(MODEL_SAVE_PATH, 'best_checkpoint.pth')))\n","model.eval()\n","\n","y_true = []\n","y_pred = []\n","print(\"Let's check results\")\n","for test_data, test_labels in test_data_loader:\n","    test_data = test_data.to(device)\n","    test_labels = test_labels.to(device)\n","    with torch.no_grad():\n","        test_preds = model(test_data)\n","    test_pred_labels = torch.argmax(test_preds, dim=1)\n","    y_true.extend(test_labels.detach().cpu().numpy())\n","    y_pred.extend(test_pred_labels.detach().cpu().numpy())\n","\n","print(classification_report(y_true, y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu.\n"]}]},{"cell_type":"code","metadata":{"id":"qW_kGAVReVz4"},"source":["   # from sklearn import metrics \n","   # from sklearn.metrics import f1_score\n","   # import numpy as np\n","   # metrics.f1_score(y_true, y_pred, labels=np.unique(y_pred))"],"execution_count":null,"outputs":[]}]}